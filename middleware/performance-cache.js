/**\n * Performance caching middleware for CarBot API endpoints\n * Implements intelligent caching strategies based on endpoint patterns\n */\n\nimport { cache, createCacheKey, hashCacheKey } from '../lib/redis-cache.js'\nimport { apiMonitor } from '../lib/performance-monitoring.js'\n\n// Cache configuration for different endpoint types\nconst CACHE_CONFIG = {\n  // Static data - long cache\n  static: {\n    ttl: 3600, // 1 hour\n    patterns: ['/api/workshops/public', '/api/static']\n  },\n  \n  // Analytics data - medium cache\n  analytics: {\n    ttl: 300, // 5 minutes\n    patterns: ['/api/analytics', '/api/dashboard/stats']\n  },\n  \n  // Dynamic data - short cache\n  dynamic: {\n    ttl: 60, // 1 minute\n    patterns: ['/api/leads', '/api/chat/recent']\n  },\n  \n  // User-specific data - very short cache\n  user: {\n    ttl: 30, // 30 seconds\n    patterns: ['/api/auth/session', '/api/user/profile']\n  },\n  \n  // Real-time data - no cache\n  realtime: {\n    ttl: 0,\n    patterns: ['/api/chat/send', '/api/webhooks', '/api/stripe/webhook']\n  }\n}\n\n// Headers that affect caching\nconst CACHE_VARY_HEADERS = ['authorization', 'x-client-key', 'user-agent']\n\n// HTTP methods that can be cached\nconst CACHEABLE_METHODS = ['GET', 'HEAD', 'OPTIONS']\n\n/**\n * Determine cache configuration for a request\n */\nfunction getCacheConfig(pathname) {\n  for (const [configName, config] of Object.entries(CACHE_CONFIG)) {\n    if (config.patterns.some(pattern => pathname.startsWith(pattern))) {\n      return { ...config, type: configName }\n    }\n  }\n  \n  // Default configuration\n  return { ttl: 120, type: 'default' }\n}\n\n/**\n * Generate cache key for request\n */\nfunction generateCacheKey(req, cacheType) {\n  const { pathname, searchParams } = new URL(req.url, 'http://localhost')\n  \n  // Base key components\n  const keyParts = [cacheType, pathname]\n  \n  // Add query parameters for GET requests\n  if (searchParams.size > 0) {\n    const sortedParams = Array.from(searchParams.entries())\n      .sort(([a], [b]) => a.localeCompare(b))\n      .map(([key, value]) => `${key}=${value}`)\n      .join('&')\n    keyParts.push(hashCacheKey(sortedParams))\n  }\n  \n  // Add user-specific data if needed\n  const userKey = req.headers.get('authorization') || req.headers.get('x-client-key')\n  if (userKey && cacheType === 'user') {\n    keyParts.push(hashCacheKey(userKey))\n  }\n  \n  return createCacheKey('api', ...keyParts)\n}\n\n/**\n * Check if response should be cached\n */\nfunction shouldCacheResponse(response, cacheConfig) {\n  // Don't cache errors (except 404 for static resources)\n  if (response.status >= 400) {\n    return response.status === 404 && cacheConfig.type === 'static'\n  }\n  \n  // Don't cache if explicitly disabled\n  const cacheControl = response.headers.get('cache-control')\n  if (cacheControl?.includes('no-cache') || cacheControl?.includes('no-store')) {\n    return false\n  }\n  \n  // Cache successful responses\n  return response.status >= 200 && response.status < 300\n}\n\n/**\n * Create cached response object\n */\nasync function createCachedResponse(response) {\n  const body = await response.text()\n  \n  return {\n    status: response.status,\n    statusText: response.statusText,\n    headers: Object.fromEntries(response.headers.entries()),\n    body,\n    timestamp: Date.now()\n  }\n}\n\n/**\n * Restore response from cached data\n */\nfunction restoreResponse(cachedData) {\n  const headers = new Headers(cachedData.headers)\n  \n  // Add cache indicators\n  headers.set('x-cache', 'HIT')\n  headers.set('x-cache-timestamp', new Date(cachedData.timestamp).toISOString())\n  \n  return new Response(cachedData.body, {\n    status: cachedData.status,\n    statusText: cachedData.statusText,\n    headers\n  })\n}\n\n/**\n * Main caching middleware\n */\nexport async function performanceCacheMiddleware(req, context) {\n  const { pathname } = new URL(req.url)\n  const method = req.method.toUpperCase()\n  \n  // Skip caching for non-cacheable methods\n  if (!CACHEABLE_METHODS.includes(method)) {\n    return null // Continue to next handler\n  }\n  \n  // Get cache configuration\n  const cacheConfig = getCacheConfig(pathname)\n  \n  // Skip caching for realtime endpoints\n  if (cacheConfig.ttl === 0) {\n    return null\n  }\n  \n  // Generate cache key\n  const cacheKey = generateCacheKey(req, cacheConfig.type)\n  \n  // Start API monitoring\n  const requestId = apiMonitor.startRequest(pathname, method)\n  \n  try {\n    // Try to get cached response\n    const cachedData = await cache.get(cacheKey)\n    \n    if (cachedData) {\n      // Return cached response\n      const response = restoreResponse(cachedData)\n      apiMonitor.endRequest(requestId, response.status)\n      return response\n    }\n    \n    // No cached response found, continue to handler\n    return null\n    \n  } catch (error) {\n    console.error('Cache middleware error:', error)\n    apiMonitor.endRequest(requestId, 500, error)\n    return null // Continue without caching\n  }\n}\n\n/**\n * Response caching middleware (to be called after handler)\n */\nexport async function cacheResponseMiddleware(req, response) {\n  const { pathname } = new URL(req.url)\n  const method = req.method.toUpperCase()\n  \n  // Skip caching for non-cacheable methods\n  if (!CACHEABLE_METHODS.includes(method)) {\n    return response\n  }\n  \n  // Get cache configuration\n  const cacheConfig = getCacheConfig(pathname)\n  \n  // Skip caching for realtime endpoints\n  if (cacheConfig.ttl === 0) {\n    return response\n  }\n  \n  // Check if response should be cached\n  if (!shouldCacheResponse(response, cacheConfig)) {\n    return response\n  }\n  \n  try {\n    // Clone response to avoid consuming the body\n    const responseClone = response.clone()\n    \n    // Generate cache key\n    const cacheKey = generateCacheKey(req, cacheConfig.type)\n    \n    // Create cached response data\n    const cachedData = await createCachedResponse(responseClone)\n    \n    // Store in cache asynchronously\n    cache.set(cacheKey, cachedData, cacheConfig.ttl).catch(error => {\n      console.error('Failed to cache response:', error)\n    })\n    \n    // Add cache headers to original response\n    const headers = new Headers(response.headers)\n    headers.set('x-cache', 'MISS')\n    headers.set('x-cache-type', cacheConfig.type)\n    headers.set('cache-control', `public, max-age=${cacheConfig.ttl}, stale-while-revalidate=${Math.floor(cacheConfig.ttl / 2)}`)\n    \n    return new Response(response.body, {\n      status: response.status,\n      statusText: response.statusText,\n      headers\n    })\n    \n  } catch (error) {\n    console.error('Response caching error:', error)\n    return response\n  }\n}\n\n/**\n * Cache invalidation utilities\n */\nexport class CacheInvalidator {\n  constructor() {\n    this.invalidationPatterns = new Map()\n  }\n  \n  /**\n   * Register cache invalidation pattern\n   */\n  registerPattern(trigger, patterns) {\n    if (!this.invalidationPatterns.has(trigger)) {\n      this.invalidationPatterns.set(trigger, [])\n    }\n    this.invalidationPatterns.get(trigger).push(...patterns)\n  }\n  \n  /**\n   * Invalidate cache based on trigger\n   */\n  async invalidate(trigger, context = {}) {\n    const patterns = this.invalidationPatterns.get(trigger)\n    if (!patterns) return\n    \n    const invalidationPromises = patterns.map(async (pattern) => {\n      try {\n        // Simple pattern matching - could be enhanced with regex\n        if (pattern.includes('*')) {\n          // TODO: Implement pattern-based cache clearing\n          console.log(`Would invalidate pattern: ${pattern}`)\n        } else {\n          await cache.delete(pattern)\n        }\n      } catch (error) {\n        console.error(`Failed to invalidate cache for pattern ${pattern}:`, error)\n      }\n    })\n    \n    await Promise.allSettled(invalidationPromises)\n  }\n}\n\n// Global cache invalidator instance\nexport const cacheInvalidator = new CacheInvalidator()\n\n// Setup common invalidation patterns\ncacheInvalidator.registerPattern('lead_created', [\n  'api:analytics:*',\n  'api:dashboard:*'\n])\n\ncacheInvalidator.registerPattern('workshop_updated', [\n  'api:static:*',\n  'api:workshops:*'\n])\n\ncacheInvalidator.registerPattern('subscription_changed', [\n  'api:user:*',\n  'api:analytics:*'\n])\n\n/**\n * Middleware factory for Next.js API routes\n */\nexport function withCache(handler, options = {}) {\n  return async (req, res) => {\n    // Apply request caching middleware\n    const cachedResponse = await performanceCacheMiddleware(req, { res })\n    \n    if (cachedResponse) {\n      // Return cached response\n      res.status(cachedResponse.status)\n      \n      // Set headers\n      for (const [key, value] of cachedResponse.headers) {\n        res.setHeader(key, value)\n      }\n      \n      return res.send(cachedResponse.body)\n    }\n    \n    // Call original handler\n    const result = await handler(req, res)\n    \n    // Note: Response caching for Next.js would need to be implemented\n    // differently since res.json() etc. send the response immediately\n    \n    return result\n  }\n}\n\n/**\n * Cache warming utility\n */\nexport async function warmAPICache() {\n  console.log('Starting API cache warming...')\n  \n  const warmupEndpoints = [\n    { path: '/api/workshops/public', method: 'GET' },\n    { path: '/api/analytics/overview', method: 'GET' },\n    { path: '/api/dashboard/stats', method: 'GET' }\n  ]\n  \n  const warmupPromises = warmupEndpoints.map(async (endpoint) => {\n    try {\n      const response = await fetch(`http://localhost:3000${endpoint.path}`, {\n        method: endpoint.method,\n        headers: { 'x-cache-warmup': 'true' }\n      })\n      \n      if (response.ok) {\n        console.log(`Warmed up: ${endpoint.path}`)\n      }\n    } catch (error) {\n      console.error(`Failed to warm up ${endpoint.path}:`, error)\n    }\n  })\n  \n  await Promise.allSettled(warmupPromises)\n  console.log('API cache warming completed')\n}\n\nexport default {\n  performanceCacheMiddleware,\n  cacheResponseMiddleware,\n  CacheInvalidator,\n  cacheInvalidator,\n  withCache,\n  warmAPICache\n}"