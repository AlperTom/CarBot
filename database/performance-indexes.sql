-- Performance optimization indexes for CarBot database\n-- These indexes are designed to optimize the most common queries\n\n-- ============================================================================\n-- LEADS TABLE OPTIMIZATIONS\n-- ============================================================================\n\n-- Primary index for leads by workshop and status (most common query)\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_leads_workshop_status_timestamp\nON leads (workshop_id, status, timestamp DESC)\nWHERE deleted_at IS NULL;\n\n-- Index for lead scoring and priority queries\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_leads_priority_score\nON leads (priority, lead_score DESC, timestamp DESC)\nWHERE deleted_at IS NULL AND status != 'archived';\n\n-- Composite index for analytics queries (date range with workshop)\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_leads_analytics\nON leads (workshop_id, timestamp, status, source_url)\nWHERE deleted_at IS NULL;\n\n-- Index for customer/client queries\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_leads_kunde_timestamp\nON leads (kunde_id, timestamp DESC)\nWHERE deleted_at IS NULL;\n\n-- Partial index for active leads only (most frequent queries)\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_leads_active\nON leads (workshop_id, timestamp DESC, priority, status)\nWHERE deleted_at IS NULL AND status IN ('new', 'contacted', 'qualified', 'in_progress');\n\n-- ============================================================================\n-- WORKSHOPS TABLE OPTIMIZATIONS\n-- ============================================================================\n\n-- Index for workshop lookup by slug (public pages)\nCREATE UNIQUE INDEX CONCURRENTLY IF NOT EXISTS idx_workshops_slug_active\nON workshops (slug)\nWHERE deleted_at IS NULL;\n\n-- Index for subscription and billing queries\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_workshops_subscription\nON workshops (subscription_plan, current_period_end, subscription_status)\nWHERE deleted_at IS NULL;\n\n-- Index for geographic queries (city-based searches)\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_workshops_location\nON workshops (city, country, subscription_status)\nWHERE deleted_at IS NULL;\n\n-- ============================================================================\n-- CHAT MESSAGES TABLE OPTIMIZATIONS\n-- ============================================================================\n\n-- Primary index for chat history by client\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_chat_messages_client_timestamp\nON chat_messages (client_key, created_at DESC, message_type);\n\n-- Index for analytics and usage tracking\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_chat_messages_analytics\nON chat_messages (client_key, created_at, message_type, response_time_ms)\nWHERE created_at > (CURRENT_DATE - INTERVAL '90 days');\n\n-- Index for conversation threads\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_chat_conversation_thread\nON chat_messages (conversation_id, created_at, message_type)\nWHERE conversation_id IS NOT NULL;\n\n-- Partial index for recent messages (performance optimization)\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_chat_messages_recent\nON chat_messages (client_key, created_at DESC)\nWHERE created_at > (CURRENT_DATE - INTERVAL '7 days');\n\n-- ============================================================================\n-- SUBSCRIPTIONS TABLE OPTIMIZATIONS\n-- ============================================================================\n\n-- Index for active subscriptions\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_subscriptions_active\nON subscriptions (status, current_period_end, workshop_id)\nWHERE status IN ('active', 'trialing', 'past_due');\n\n-- Index for billing and invoice queries\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_subscriptions_billing\nON subscriptions (stripe_customer_id, status, current_period_end);\n\n-- Index for subscription plan analytics\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_subscriptions_plan_analytics\nON subscriptions (plan_id, status, created_at, current_period_end);\n\n-- ============================================================================\n-- AI USAGE LOGS OPTIMIZATIONS\n-- ============================================================================\n\n-- Primary index for usage tracking and billing\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_usage_client_date\nON ai_usage_logs (client_key, created_at DESC, tokens_used);\n\n-- Index for performance monitoring\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_usage_performance\nON ai_usage_logs (client_key, response_time_ms, created_at DESC)\nWHERE created_at > (CURRENT_DATE - INTERVAL '30 days');\n\n-- Index for cost calculation\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_ai_usage_costs\nON ai_usage_logs (client_key, created_at, tokens_used, model_used)\nWHERE created_at > (CURRENT_DATE - INTERVAL '1 month');\n\n-- ============================================================================\n-- EMAIL LOGS OPTIMIZATIONS\n-- ============================================================================\n\n-- Index for email delivery tracking\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_email_logs_delivery\nON email_logs (workshop_id, status, created_at DESC);\n\n-- Index for email analytics\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_email_logs_analytics\nON email_logs (email_type, status, created_at)\nWHERE created_at > (CURRENT_DATE - INTERVAL '90 days');\n\n-- ============================================================================\n-- WEBHOOK LOGS OPTIMIZATIONS\n-- ============================================================================\n\n-- Index for webhook processing and debugging\nCREATE INDEX CONCURRENTLY IF NOT EXISTS idx_webhook_logs_processing\nON webhook_logs (source, status, created_at DESC)\nWHERE created_at > (CURRENT_DATE - INTERVAL '7 days');\n\n-- ============================================================================\n-- PERFORMANCE MONITORING VIEWS\n-- ============================================================================\n\n-- View for workshop performance metrics\nCREATE OR REPLACE VIEW workshop_performance_summary AS\nSELECT \n    w.id as workshop_id,\n    w.name as workshop_name,\n    w.slug,\n    COUNT(l.id) as total_leads_30d,\n    COUNT(CASE WHEN l.status IN ('qualified', 'converted') THEN 1 END) as qualified_leads_30d,\n    ROUND(AVG(l.lead_score), 2) as avg_lead_score,\n    COUNT(CASE WHEN l.created_at > CURRENT_DATE - INTERVAL '7 days' THEN 1 END) as leads_7d,\n    ROUND(\n        COUNT(CASE WHEN l.status IN ('qualified', 'converted') THEN 1 END)::numeric / \n        NULLIF(COUNT(l.id), 0) * 100, 2\n    ) as conversion_rate_pct\nFROM workshops w\nLEFT JOIN leads l ON w.id = l.workshop_id \n    AND l.created_at > CURRENT_DATE - INTERVAL '30 days'\n    AND l.deleted_at IS NULL\nWHERE w.deleted_at IS NULL\nGROUP BY w.id, w.name, w.slug;\n\n-- View for API performance metrics\nCREATE OR REPLACE VIEW api_performance_summary AS\nSELECT \n    client_key,\n    COUNT(*) as total_requests_24h,\n    ROUND(AVG(response_time_ms), 2) as avg_response_time_ms,\n    ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY response_time_ms), 2) as p95_response_time_ms,\n    SUM(tokens_used) as total_tokens_24h,\n    COUNT(CASE WHEN response_time_ms > 2000 THEN 1 END) as slow_requests,\n    ROUND(\n        COUNT(CASE WHEN response_time_ms > 2000 THEN 1 END)::numeric / \n        COUNT(*) * 100, 2\n    ) as slow_request_rate_pct\nFROM ai_usage_logs\nWHERE created_at > CURRENT_TIMESTAMP - INTERVAL '24 hours'\nGROUP BY client_key;\n\n-- ============================================================================\n-- DATABASE MAINTENANCE FUNCTIONS\n-- ============================================================================\n\n-- Function to analyze table statistics for query planner\nCREATE OR REPLACE FUNCTION refresh_table_statistics()\nRETURNS void AS $$\nBEGIN\n    ANALYZE leads;\n    ANALYZE workshops;\n    ANALYZE chat_messages;\n    ANALYZE subscriptions;\n    ANALYZE ai_usage_logs;\n    ANALYZE email_logs;\n    ANALYZE webhook_logs;\n    \n    RAISE NOTICE 'Table statistics refreshed at %', NOW();\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Function to get slow query recommendations\nCREATE OR REPLACE FUNCTION get_performance_recommendations()\nRETURNS TABLE (\n    table_name text,\n    issue_type text,\n    recommendation text,\n    priority text\n) AS $$\nBEGIN\n    RETURN QUERY\n    WITH table_stats AS (\n        SELECT \n            schemaname,\n            tablename,\n            n_tup_ins + n_tup_upd + n_tup_del as total_modifications,\n            n_tup_hot_upd,\n            n_dead_tup,\n            last_vacuum,\n            last_analyze\n        FROM pg_stat_user_tables\n        WHERE schemaname = 'public'\n    )\n    SELECT \n        ts.tablename::text,\n        'maintenance'::text,\n        CASE \n            WHEN ts.last_vacuum < CURRENT_TIMESTAMP - INTERVAL '7 days' \n                THEN 'Table needs VACUUM - last vacuumed ' || \n                     COALESCE(ts.last_vacuum::text, 'never')\n            WHEN ts.last_analyze < CURRENT_TIMESTAMP - INTERVAL '1 day'\n                THEN 'Table needs ANALYZE for query optimization'\n            WHEN ts.n_dead_tup > 1000\n                THEN 'High number of dead tuples (' || ts.n_dead_tup || ') - consider VACUUM'\n            ELSE 'Table maintenance up to date'\n        END::text,\n        CASE\n            WHEN ts.n_dead_tup > 10000 THEN 'HIGH'::text\n            WHEN ts.n_dead_tup > 1000 THEN 'MEDIUM'::text\n            ELSE 'LOW'::text\n        END::text\n    FROM table_stats ts\n    WHERE ts.tablename IN ('leads', 'workshops', 'chat_messages', 'subscriptions', 'ai_usage_logs')\n    ORDER BY \n        CASE \n            WHEN ts.n_dead_tup > 10000 THEN 1\n            WHEN ts.n_dead_tup > 1000 THEN 2\n            ELSE 3\n        END,\n        ts.total_modifications DESC;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- ============================================================================\n-- AUTOMATED MAINTENANCE JOBS\n-- ============================================================================\n\n-- Note: These would typically be run by a cron job or scheduled task\n-- Function to cleanup old data\nCREATE OR REPLACE FUNCTION cleanup_old_data()\nRETURNS void AS $$\nBEGIN\n    -- Clean up old chat messages (keep last 90 days)\n    DELETE FROM chat_messages \n    WHERE created_at < CURRENT_DATE - INTERVAL '90 days'\n    AND message_type != 'lead_generation'; -- Keep lead generation messages longer\n    \n    -- Clean up old webhook logs (keep last 30 days)\n    DELETE FROM webhook_logs \n    WHERE created_at < CURRENT_DATE - INTERVAL '30 days';\n    \n    -- Clean up old email logs (keep last 180 days for compliance)\n    DELETE FROM email_logs \n    WHERE created_at < CURRENT_DATE - INTERVAL '180 days'\n    AND status = 'sent'; -- Keep failed sends for debugging\n    \n    -- Archive old AI usage logs to separate table (if needed for cost analysis)\n    -- This is just a placeholder - implement according to retention policy\n    \n    RAISE NOTICE 'Old data cleanup completed at %', NOW();\nEND;\n$$ LANGUAGE plpgsql;\n\n-- ============================================================================\n-- PERFORMANCE MONITORING QUERIES\n-- ============================================================================\n\n-- Query to check index usage\n-- SELECT \n--     schemaname,\n--     tablename,\n--     attname,\n--     n_distinct,\n--     correlation\n-- FROM pg_stats \n-- WHERE schemaname = 'public' \n--   AND tablename IN ('leads', 'workshops', 'chat_messages')\n-- ORDER BY tablename, attname;\n\n-- Query to find unused indexes\n-- SELECT \n--     schemaname,\n--     tablename,\n--     indexname,\n--     idx_scan,\n--     idx_tup_read,\n--     idx_tup_fetch\n-- FROM pg_stat_user_indexes \n-- WHERE schemaname = 'public'\n--   AND idx_scan < 10\n-- ORDER BY idx_scan;\n\n-- Query to check table bloat\n-- SELECT \n--     schemaname,\n--     tablename,\n--     n_dead_tup,\n--     n_live_tup,\n--     ROUND(n_dead_tup::numeric / NULLIF(n_live_tup + n_dead_tup, 0) * 100, 2) as bloat_ratio\n-- FROM pg_stat_user_tables \n-- WHERE schemaname = 'public'\n-- ORDER BY bloat_ratio DESC NULLS LAST;\n\nCOMMIT;"